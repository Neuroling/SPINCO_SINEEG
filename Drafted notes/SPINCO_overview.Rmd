---
title: "Speech-in-noise comprehension (SPINCO)"
author: "G.Fraga Gonzalez"
date: "`r Sys.Date()`"
output:
  html_document:
    code_folding: hide
    toc: yes
    toc_depth: 3
    toc_float:
      collapsed: no
runhead: SPINCO
abstract: 'Overview of ongoing projects at Neurolinguistics group (University of Zurich) '
editor_options: 
  markdown: 
    wrap: 72
---

<!-- To unfold code in specific chunks use Chunk options: class.source = 'fold-show' -->

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(gridExtra)
library(dplyr)
library(plotly)
library(ggplot2)
library(nomnoml)
library(kableExtra)
library(DT) # for saving tables
```

<!-- ## Projects {.tabset} -->

## Projects {.tabset} 

### Overview

```{nomnoml flowchart, echo = FALSE, out.height=400,out.width=850}
# https://cran.r-project.org/web/packages/nomnoml/readme/README.html
#fontSize: 6
#arrowSize: .5
#stroke: black
#.box: dashed center
#.comment: fill=Wheat empty bold
#background: FloralWhite
#lineWidth: 1
#direction: right
#leading: 1.25
#lineWidth: .75
#padding: 8
#spacing: 40
#zoom: 3
  
[<database>SPINCO]-> EEG[<comment>SINEEG]
[<database>SPINCO]-> online[<comment>SINON]
  
  [SINON]-->Rmd [database | words | pseudowords] 
  [database]--> Matlab[Manipulations | noise-vocoded | in speech-shaped noise]
  [Manipulations] --> .m[SNR | x 5 Lvls] 
  [SNR | x 5 Levls] -> Gorilla[Tasks | LD | 2FC | pict match]
  
  [<comment>SINEEG]-->Openvibe[Real-time EEG]
  [<comment>SINEEG]-->Matlab[ Manipulation | noise-vocoded]
  [Manipulation] --> .m[SNR. | 3 x Lvls]
  [Real-time EEG] --> [brain-states | alpha | beta-connect?]
  [brain-states] --> [stim trigger]
  [SNR.] -->  [stim trigger]
  [stim trigger] -> psyexp [Task | Lexical Decision]
  

```

### Data storage

Main directories highlighted in pink: (1) Documents, presentations and publications (2) scripts (3) data, results, statistics.

All scripts regularly backed up to a private repo in Github

```{nomnoml, echo = FALSE, out.height=400,out.width=850}
# https://cran.r-project.org/web/packages/nomnoml/readme/README.html
#fontSize: 6
#arrowSize: .5
#stroke: black
#.box: dashed center
#.comment: fill=Wheat empty bold
#.client: fill=LavenderBlush empty bold
#background: FloralWhite
#lineWidth: 1
#direction: right
#leading: .75
#lineWidth: .75
#padding: 5
#spacing: 0
#zoom: 2
  
[<state>user]-> local[<comment> PC |]
[PC] --> cloud [<client>OneDrive/Sharepoint | spinco_documentation]
[user]-> remote[<comment>Linux | 130.60.236.20 |130.60.238.20]
[PC] -- [<database> SMB-share ]
 
[<database> SMB-share] <-> private [<client>gfraga | scripts]
  [gfraga | scripts]-:> push2web [<state>github repo]

[<database> SMB-share] <->  [<client>spinco_data |raw, final outputs, long-term ]

[Linux] -- [<database> NFS-share | heavy processing]
[Linux] -- [<database> SMB-share]
[<database> NFS-share] <-> shared [mnt/spinco |intermediate and final outputs]
[<database> NFS-share] <-> private [mnt/gfraga-data]
[<database> NFS-share] <--> shared [spinco_data]
```

<!-- ## Stimuli {.tabset} -->

## Stimuli {.tabset} 

### Recordings

Words and pseudowords were recorded in shuffled order in a single session by
dr. D. Friedrichs (at LIRI, UZH). The session recorded video and .wav files at 44100 Hz; 24 bits per sample.

```{nomnoml , echo = FALSE, out.height=400,out.width=850}
# From  https://nomnoml.com/
#arrowSize: 1
#bendSize: 0.3
#direction:  right 
#gutter: 15
#edgeMargin: 0
#gravity: 1
#edges: hard | rounded
#background: transparent
#fill: #eee8d5; #fdf6e3
#fillArrows: false
#font: Calibri
#fontSize: 12
#leading: 1.25
#lineWidth: 1.5
#padding: 8
#spacing: 45
#stroke: #33322E
#title: filename
#zoom: 1
#acyclicer: greedy
#ranker: network-simplex | tight-tree | longest-path
#.box: fill=#8f8 dashed
#.blob: visual=ellipse title=bold

[<usecase>raw | versions] ->  [<table> Separate files (prorrec) | words | pseudowords]
[<table> Separate files (prorrec)] -->  [<state>inspect | +trim]

[inspect ] --> [<actor>audiocheck|plots]

[<actor>audiocheck] --> if OK  [<abstract>Audacity macro | trunc silence | fade ends | add silence | normalize loudness]
  [<abstract>Audacity macro] --> [Experiment]
    [<abstract>Experiment]  -->  [<state>clear]
    [<abstract>Experiment] --> [<state>in SSN]
    [<abstract>Experiment] --> [<state>vocoder]
      [<state>vocoder] -- Lvls[<start>st.]
      [<state>in SSN] -- SNRs[<start>st]
[<actor>audiocheck] <--> not OK?[<abstract>audioLabeler app | or discard]
      
```
#### **Audio labeler** (optional: recommended to use Audacity instead)

Matlab app to apply speech detection in one or more wav files and to
manually adjust the output as a label.

1.   Type: **AudioLabeler** in command line to initialize the app

2.   Go to Label and **load** one or several audio files

3.   **Select all** files and click on Speech detector. This will open a
    new tab with the option to run speech detector. Run it in all files

4.   Now a new **label SpeechDetected** has been created in the ROI
    labels panel.

5.   To **adjust** the label click in one audio file and then in the
    yellow segment marked by the speech detector . If it is not adjust
    the edges of the highlight and then click away in the panel below.
    Make sure the label doesn't reset to the original size!

6.   If you find a '**click**' add a new label called 'click' and select
    a short segment around it. Mark it as 'true' so it is saved.

7.   **Saving** the output. One option is to select all files and then
    click Labels/Export to workspace. This will create a new variable:
    labeledSet_hhmmss (time stamped)

8.   Run **script to use the label info** , transform the click segment
    (if any ) to zero and trim the file.

## SINON {.tabset} 

### Noise generation

```{nomnoml, echo = FALSE, out.height=400,out.width=850}
# https://cran.r-project.org/web/packages/nomnoml/readme/README.html
#fontSize: 6
#arrowSize: .5
#stroke: black
#.box: dashed center
#.comment: fill=Wheat empty bold
#.client: fill=LavenderBlush empty bold
#background: FloralWhite
#lineWidth: 1
#direction: right
#leading: 1.25
#lineWidth: .75
#padding: 8
#spacing: 40
#zoom: 3
[<database>audio |files  normalized to X db | head + tail silence] --> each [filtered]
  [filtered] --> all [<comment>concatenate]
    [<comment>concatenate] --> [<comment>long SSN]
      [long SSN] --> file loop [<client>SSN | file cuts + head | match file rms]
        
  [<database>SSN] --> [<choice> SNR lev | adjust db lv]
    [SNR lev ]-> [SiSSN]
    [filtered ] -> [SiSSN | signal*(0.99/max(abs(signal)))]
      [SiSSN]-> audacity [<usecase> SiSSN. | norm perceived loudness]

[<database>audio |files  normalized to X db | head + tail silence] --> each [SNR ctrl | n channels]
 [<client>SNR ctrl | n channels] --> [<choice>filter bank | greenwood spacing]  
  [filter bank | Greenwood spacing]--> [<client>vocoder]
        [vocoder]--> [NV speech]
        [NV speech]--> audacity[<usecase>NV speech.| norm perceived loudness]
   
```

### Trial sequences

```{nomnoml, echo = FALSE, out.height=400,out.width=850}
# From  https://nomnoml.com/
#arrowSize: 1
#bendSize: 0.3
#direction:  right 
#gutter: 15
#edgeMargin: 0
#gravity: 1
#edges: hard | rounded
#background: transparent
#fill: #eee8d5; #fdf6e3
#fillArrows: false
#font: Calibri
#fontSize: 12
#leading: 1.25
#lineWidth: 1.5
#padding: 8
#spacing: 45
#stroke: #33322E
#title: filename
#zoom: 1
#acyclicer: greedy
#ranker: network-simplex | tight-tree | longest-path
#.box: fill=#8f8 dashed
#.blob: visual=ellipse title=bold

[<usecase>MATCH | subsets] -> R[<table>SINON_spreadsheets_LD | distribute words/pseudo; distribute snr; list file names]
[<state>SINON_spreadsheets_LD]-->R[<table>SINON_spreadsheets_LD_Gorilla | added formatting]
[<state>SINON_spreadsheets_LD_Gorilla | added formatting] --> R[<table> SINON_spreadsheets_LD_Gorila_cbxxx | copies with counterbalanced block order]

[<state>SINON_spreadsheets_LD]-->R[<state>copy audiofiles | copy mp3s of trials to folder]

[<state>SINON_spreadsheets_LD_Gorilla]-->.m[<state>table audiofiles | summary rms and duration]
[<state>copy audiofiles]-->[<state>table audiofiles | summary rms and duration]
[<state>table audiofiles]-->R[<state>summary plots]

```
<!-- ### Design -->

<!-- ```{nomnoml, echo = FALSE, out.height=400,out.width=850} -->
<!-- # https://cran.r-project.org/web/packages/nomnoml/readme/README.html -->
<!-- #fontSize: 6 -->
<!-- #arrowSize: .5 -->
<!-- #stroke: black -->
<!-- #.box: dashed center -->
<!-- #.comment: fill=lightyellow empty bold -->
<!-- #lineWidth: 1 -->
<!-- #direction: right -->
<!-- #leading: 1.25 -->
<!-- #lineWidth: .75 -->
<!-- #padding: 8 -->
<!-- #spacing: 40 -->
<!-- #zoom: 2 -->
<!-- #direction: down -->

<!-- [<database>SINON| manipulations]-> [Within ss] -->
<!--   [Within ss] -  [Item type | word | pseudo] -->
<!--   [Within ss]   ['Noise' type | vocoding | speech-shaped noise] -->
<!--   [Within ss]  [SNR | 1 | 2| 3| 4| 5] -->

<!-- [<database>SINON| manipulations]-> [Between ss] -->
<!--   [Between ss]   [Task | Lexical decision | 2FC | Pict match] -->


<!-- ``` -->
 